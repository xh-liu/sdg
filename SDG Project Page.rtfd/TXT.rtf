{\rtf1\ansi\ansicpg1252\cocoartf2580
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 Georgia;\f1\fswiss\fcharset0 Helvetica;\f2\fnil\fcharset0 Georgia-Bold;
\f3\fswiss\fcharset0 Helvetica-Bold;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red5\green61\blue204;\red133\green0\blue2;
\red71\green71\blue71;\red7\green64\blue128;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;\cssrgb\c0\c33896\c83855;\cssrgb\c60000\c0\c0;
\cssrgb\c34902\c34902\c34902;\cssrgb\c0\c32852\c57488;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}}
{\info
{\title SDEdit Project Page}}\vieww51000\viewh28800\viewkind0
\deftab720
\pard\pardeftab720\sl600\sa268\qc\partightenfactor0

\f0\fs40 \cf2 \expnd0\expndtw0\kerning0
More Control for Free! Image Synthesis with Semantic Diffusion Guidance\
\pard\pardeftab720\sl450\qc\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://xh-liu.github.io/"}}{\fldrslt 
\fs34 \cf3 Xihui Liu}}
\f1\fs25\fsmilli12800 \cf3 \super 1
\f0\fs34 \cf6 \nosupersub      {\field{\*\fldinst{HYPERLINK "https://scholar.google.com/citations?user=_kJ-zUYAAAAJ&hl=en"}}{\fldrslt \cf3 Dong Huk Park}}
\f1\fs25\fsmilli12800 \cf3 \super 1
\f0\fs34 \nosupersub      {\field{\*\fldinst{HYPERLINK "http://people.eecs.berkeley.edu/~sazadi/index.html"}}{\fldrslt Samaneh Azadi}}
\f1\fs25\fsmilli12800 \super 1
\f0\fs34 \nosupersub      Gong Zhang
\f1\fs25\fsmilli12800 \super 2
\f0\fs34 \nosupersub \
Arman Chopikyan
\f1\fs25\fsmilli12800 \super 2
\f0\fs34 \nosupersub      {\field{\*\fldinst{HYPERLINK "https://scholar.google.com/citations?user=JnvYwo8AAAAJ&hl=en"}}{\fldrslt Yuxiao Hu}}
\f1\fs25\fsmilli12800 \super 2
\f0\fs34 \nosupersub      {\field{\*\fldinst{HYPERLINK "https://www.humphreyshi.com/"}}{\fldrslt Humphrey Shi}}
\f1\fs25\fsmilli12800 \super 2
\f0\fs34 \nosupersub      {\field{\*\fldinst{HYPERLINK "https://anna-rohrbach.net/"}}{\fldrslt Anna Rohrach}}
\f1\fs25\fsmilli12800 \super 1
\f0\fs34 \nosupersub      {\field{\*\fldinst{HYPERLINK "https://people.eecs.berkeley.edu/~trevor/"}}{\fldrslt Trevor Darrell}}
\f1\fs25\fsmilli12800 \super 1
\f0\fs30 \cf6 \nosupersub \
\pard\pardeftab720\qc\partightenfactor0

\f1\fs25\fsmilli12800 \cf5 \super 1
\f0\fs30 \cf2 \nosupersub UC Berkeley\'a0\'a0\'a0  
\f1\fs25\fsmilli12800 \cf5 \super 2
\f0\fs30 \cf2 \nosupersub Picsart AI Research \
\pard\pardeftab720\sl450\qc\partightenfactor0

\f2\b \cf3 Paper\cf2  | {\field{\*\fldinst{HYPERLINK "https://docs.google.com/presentation/d/1cMB7dcKoJ4s6oeqkbo6qNBw8u4Un2rprFVgFIkPVxv8/edit?usp=sharing"}}{\fldrslt \cf3 Slides}} | \cf3 GitHub\cf2  | \cf3 Demo
\f0\b0 \cf2 \
\pard\pardeftab720\sl300\partightenfactor0

\fs20 \cf2 \
\pard\pardeftab720\sl450\sa300\qj\partightenfactor0

\fs30 \cf2 We propose a unified framework for fine-grained controllable image synthesis with either language guidance or image guidance, or both language and image guidance.\
Our semantic guidance can be injected to a pertained unconditional diffusion model without re-training or fine-tuning the diffusion model.\
The language guidance can be applied to any dataset without text annotations.{\field{\*\fldinst{HYPERLINK "file:///Users/xihui/Documents/project_page/SDEdit%20Project%20Page_files/teaser.jpg"}}{\fldrslt 
\f2\b\fs20 \cf4 \
}}\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardeftab720\pardirnatural\qc\partightenfactor0
\cf2 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardeftab720\pardirnatural\qc\partightenfactor0

\f1\fs24 \cf0 \kerning1\expnd0\expndtw0 {{\NeXTGraphic teaser_v3.pdf \width14540 \height6320 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardeftab720\pardirnatural\qc\partightenfactor0

\f0\fs20 \cf2 \expnd0\expndtw0\kerning0
\
\pard\pardeftab720\sl300\partightenfactor0
\cf2 \
\pard\pardeftab720\sl450\sa300\partightenfactor0

\fs30 \cf2 \
\pard\pardeftab720\sl450\qc\partightenfactor0

\f2\b\fs36 \cf2 Abstract
\f0\b0\fs30 \
\pard\pardeftab720\sl450\sa300\qj\partightenfactor0
\cf2 Controllable image synthesis models allow creation of diverse images based on text instructions or guidance from an example image. Recently, denoising diffusion probabilistic models have been shown to generate more realistic imagery than prior methods, and have been successfully demonstrated in unconditional and class-conditional settings. We explore fine-grained, continuous control of this model class, and introduce a novel unified framework for semantic diffusion guidance, which allows either language or image guidance, or both.  Guidance is injected into a pretrained unconditional diffusion model using the gradient of image-text or image matching scores.  We explore CLIP-based textual guidance as well as both content and style-based image guidance in a unified form. Our text-guided synthesis approach can be applied to datasets without associated text annotations. We conduct experiments on FFHQ and LSUN datasets, and show results on fine-grained text-guided image synthesis, synthesis of images related to a style or content example image, and examples with both textual and image guidance. \
\pard\pardeftab720\sl450\sa300\partightenfactor0
\cf2 \
\pard\pardeftab720\sl450\sa300\qc\partightenfactor0

\f2\b\fs36 \cf2 Semantic Diffusion Guidance
\f0\b0\fs30 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardeftab720\pardirnatural\partightenfactor0

\fs20 \cf2 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardeftab720\pardirnatural\qc\partightenfactor0

\f1\fs24 \cf0 \kerning1\expnd0\expndtw0 {{\NeXTGraphic pipeline_v4.pdf \width8320 \height4520 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardeftab720\pardirnatural\qc\partightenfactor0
\cf0 \
\
\

\f3\b\fs36 \
Image Synthesis with Language Guidance\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardeftab720\pardirnatural\qc\partightenfactor0

\f1\b0\fs24 \cf0 {{\NeXTGraphic result_l.pdf \width12880 \height7560 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardeftab720\pardirnatural\qc\partightenfactor0
\cf0 \
\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardeftab720\pardirnatural\qc\partightenfactor0

\f2\b\fs36 \cf2 \expnd0\expndtw0\kerning0
Image Synthesis with Image Guidance\
\

\f1\b0\fs24 \cf0 \kerning1\expnd0\expndtw0 {{\NeXTGraphic result_v.pdf \width13160 \height10980 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}
\f2\b\fs36 \cf2 \expnd0\expndtw0\kerning0
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardeftab720\pardirnatural\qc\partightenfactor0

\f0\b0\fs30 \cf2 \
\
Our image guidance can also be a style image guidance and out-of-domain image guidance, as shown below.\
\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardeftab720\pardirnatural\qc\partightenfactor0

\f1\fs24 \cf0 \kerning1\expnd0\expndtw0 {{\NeXTGraphic result_v_2.pdf \width13280 \height2000 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardeftab720\pardirnatural\qc\partightenfactor0

\f0\fs30 \cf2 \expnd0\expndtw0\kerning0
\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardeftab720\pardirnatural\qc\partightenfactor0

\f2\b\fs36 \cf2 \
Image Synthesis with Language Guidance + Image Guidance\
\

\f1\b0\fs24 \cf0 \kerning1\expnd0\expndtw0 {{\NeXTGraphic result_vl.pdf \width13620 \height6400 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardeftab720\pardirnatural\qc\partightenfactor0

\f0\fs30 \cf2 \expnd0\expndtw0\kerning0
\
\
\
Examples with same language guidance + different image guidance.\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardeftab720\pardirnatural\qc\partightenfactor0

\f1\fs24 \cf0 \kerning1\expnd0\expndtw0 {{\NeXTGraphic result_vl_2.pdf \width9820 \height3460 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardeftab720\pardirnatural\qc\partightenfactor0

\f0\fs30 \cf2 \expnd0\expndtw0\kerning0
\
\
\
Examples with different language guidance + same image guidance.\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardeftab720\pardirnatural\qc\partightenfactor0

\f1\fs24 \cf0 \kerning1\expnd0\expndtw0 {{\NeXTGraphic result_vl_3.pdf \width9820 \height5200 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardeftab720\pardirnatural\qc\partightenfactor0

\f0\fs30 \cf2 \expnd0\expndtw0\kerning0
\
\pard\pardeftab720\sl300\partightenfactor0

\fs20 \cf2 \
\
\pard\pardeftab720\sl450\partightenfactor0

\fs30 \cf2 Related Work\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl450\partightenfactor0
\ls1\ilvl0\cf2 \kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
Ho, Jonathan, Ajay Jain, and Pieter Abbeel {\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/2006.11239"}}{\fldrslt \cf4 "Denoising Diffusion Probabilistic Models"}}, Proceedings of the 34th Annual Conference on Neural Information Processing Systems, 2020. \
\ls1\ilvl0\kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}Prafulla Dhariwal, and Alex Nichol \'93{\field{\*\fldinst{HYPERLINK "https://arxiv.org/abs/2105.05233"}}{\fldrslt Diffusion Models Beat GANs on Image Synthesis}}\'94, \expnd0\expndtw0\kerning0
Proceedings of the 35th Annual Conference on Neural Information Processing Systems, 2021. 
\fs20 \
\pard\pardeftab720\sl300\partightenfactor0
\cf2 \
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardeftab720\pardirnatural\qc\partightenfactor0

\f1\fs24 \cf0 \kerning1\expnd0\expndtw0 \

\itap1\trowd \taflags0 \trgaph108\trleft-108 \trbrdrt\brdrnil \trbrdrl\brdrnil \trbrdrt\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth16000\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadl0 \clpadr0 \gaph\cellx8640
\pard\intbl\itap1\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardeftab720\pardirnatural\qc\partightenfactor0

\f0\fs30 \cf2 \expnd0\expndtw0\kerning0
\
\
\cell \lastrow\row
}